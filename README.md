알겠습니다. [cite_start]심사위원들이 프로젝트의 구체적인 소스 코드는 모른 채, 오직 **'MINDY' 서비스 기획서(1분과 소개자료) [cite: 1-4]** 내용만을 바탕으로 기술적인 측면을 질문한다고 가정하고, 날카로운 질문 5가지를 구성해 보았습니다.

---

## 🤖 AI 챗봇 및 인프라 관련 예상 질문 5가지

### Q1. (AI 모델 및 비용)
[cite_start]"AI 챗봇을 통한 상담 [cite: 3]이 핵심인데, 구체적으로 어떤 LLM(거대 언어 모델)을 기반으로 하셨나요? (예: GPT-4o, Llama 3 등) [cite_start]특히 CBT(인지행동치료) [cite: 3][cite_start]나 PHQ-9 [cite: 3] 같은 전문적인 영역을 다루려면 상당한 수준의 AI 성능이 필요합니다. [cite_start]**선택한 AI 모델의 기술적 기준은 무엇이었으며, AI API 호출에 드는 비용을 회당 5,000원이라는 저렴한 상담비 [cite: 3]로 어떻게 감당할 계획이신가요?**"

> **A1. 추천 답변:**
> "저희는 **비용과 성능의 균형**을 최우선으로 고려했습니다.
>
> 1.  **모델 선택:** 내담자의 감정을 공감하고 CBT 분석을 수행하는 핵심 기능에는 **고성능 모델(예: GPT-4o-mini)**을 사용하고, 일상적인 대화나 단순 정보 요약에는 **경량 모델**을 사용하는 하이브리드 방식을 채택했습니다.
> 2.  **비용 감당:** 저희 수익 모델은 내담자에게 받는 5,000원에만 의존하지 않습니다. 핵심은 **'인턴 상담사의 수련비'**입니다. 기존에 인턴 상담사가 지불하던 고액의 수련비를 저희 플랫폼을 통해 대폭 낮춰주고, 여기서 발생하는 수수료가 AI 운영 비용을 포함한 주 수익원이 됩니다. 따라서 내담자의 AI 이용 비용은 사실상 '고객 유치(Acquisition) 비용'에 가깝습니다."

---

### Q2. (실시간 통신 및 리소스 관리)
"AI 챗봇과 사용자가 실시간으로 대화를 주고받아야 합니다. 이 실시간 통신은 **어떤 기술(예: WebSocket, SSE)을 기반으로 구현하셨나요?** 만약 AI가 답변을 생성하는 도중에 사용자가 앱을 강제 종료하거나 네트워크가 끊긴다면, **서버에서는 이미 시작된 AI 작업을 즉시 중단하여 불필요한 리소스와 비용 낭비를 막는 기술적인 장치**도 마련되어 있나요?"

> **A2. 추천 답변:**
> "매우 중요한 지적입니다. 저희는 **WebSocket**을 기반으로 실시간 양방향 통신을 구현했습니다.
>
> 또한 리소스 낭비를 막기 위해, 사용자가 채팅방에 입장할 때마다 **'AbortController'(요청 중단 제어기)**를 생성하고 서버의 세션 맵(Map)에 저장합니다.
>
> 만약 사용자가 '답변 중지'를 누르거나, 웹소켓 연결이 비정상적으로 끊어지는(`disconnect`) 이벤트가 감지되면, 서버는 즉시 해당 세션의 `AbortController`를 찾아 `.abort()` 신호를 보냅니다. 이 신호는 AI 모델(LLM) API 호출까지 전파되어, 진행 중이던 답변 생성을 즉시 중지시킵니다. 이를 통해 불필요한 AI 토큰 비용과 서버 리소스 낭비를 원천적으로 차단합니다."

---

### Q3. (데이터베이스 설계)
"MINDY 서비스는 **'사용자 계정/상담사 정보/예약'** 같은 정형 데이터와, **'AI 채팅 내역/설문지 응답'** 같은 비정형 데이터가 공존합니다. 이 두 가지 성격이 다른 데이터를 **하나의 데이터베이스로 처리하셨나요? 아니면 별도의 데이터베이스(예: 관계형 DB와 NoSQL)를 목적에 맞게 분리하여 사용하셨나요?** 후자라면, 왜 그렇게 설계하셨는지 기술적인 이점을 설명해 주세요."

> **A3. 추천 답변:**
> "저희는 데이터의 성격에 맞춰 **듀얼 데이터베이스 구조**를 선택했습니다.
>
> 1.  **PostgreSQL (관계형 DB):** '사용자-상담사-예약' 정보처럼 데이터 무결성과 정합성이 중요한 정형 데이터는 **PostgreSQL**로 관리합니다. 상담 예약 같은 트랜잭션 처리에 유리합니다.
> [cite_start]2.  **MongoDB (NoSQL):** 반면, '채팅 메시지'나 'CBT 분석 결과' [cite: 3]처럼 스키마가 유연하고, 쓰기(Write)가 빈번하며, 대화별로 묶어서 통째로 읽어오는 데이터는 **MongoDB**에 저장합니다.
>
> 이 구조를 통해, 정형 데이터는 **안정적**으로, 비정형(문서) 데이터는 **유연하고 빠르**게 처리할 수 있었습니다. 만약 채팅 메시지까지 관계형 DB로 처리했다면, 매번 복잡한 Join 연산으로 인해 AI 채팅방의 응답 속도가 현저히 느려졌을 것입니다."

---

### Q4. (보안 및 민감정보 처리)
"심리 상담 앱은 사용자의 가장 민감한 개인정보를 다룹니다. [cite_start]**내담자의 채팅 내역, 우울/불안 진단 설문 결과 [cite: 3] 같은 데이터를 서버에 저장할 때, 어떤 기술적 보안 조치를 적용하셨나요?** 단순히 DB 접근 암호 외에, 데이터 자체를 암호화하거나 접근 제어를 엄격하게 관리하는 특별한 아키텍처가 있는지 궁금합니다."

> **A4. 추천 답변:**
> "저희는 '최소 권한 원칙'과 '데이터 암호화'를 기준으로 설계했습니다.
>
> 1.  **전송 구간 암호화:** 클라이언트(앱)와 서버 간의 모든 통신은 **TLS(SSL)**를 통해 암호화됩니다.
> 2.  **민감정보 암호화 (At-Rest):** DB에 저장되는 사용자 비밀번호는 **Bcrypt**를 사용해 단방향 해시 암호화하며, 복호화가 불가능합니다. 또한 채팅 내역이나 설문 결과 같은 핵심 민감정보는 DB 필드 레벨에서 **대칭키(AES-256) 암호화**를 적용하여, 만약 DB가 통째로 유출되더라도 내용을 파악할 수 없게 했습니다.
> 3.  **인증 및 인가:** 모든 API 요청은 **JWT(JSON Web Token)** 기반으로 인증되며, 인턴 상담사나 슈퍼바이저가 내담자 정보에 접근할 때도 본인에게 할당된 내담자의 정보 외에는 절대 접근할 수 없도록 서버 로직에서 엄격하게 인가를 제어합니다."

---

### Q5. (AI의 위험 탐지 및 대응)
[cite_start]"기획서에 'AI 챗봇이 내담자 정보를 사전에 파악한다' [cite: 3]고 하셨습니다. 만약 AI가 대화 중 **자해나 자살 같은 고위험(High-risk) 징후를 감지했을 때, 기술적으로 어떤 프로세스가 자동으로 실행되나요?** AI가 단순히 '힘내세요'라고 응답하는 것을 넘어, 즉각적으로 인턴 상담사나 슈퍼바이저에게 알림을 보내는 **'기술적 에스컬레이션(Escalation)'** 체계가 구현되어 있습니까?"

> **A5. 추천 답변:**
> "네, 그것이 저희 AI의 가장 중요한 안전장치입니다. 저희는 두 단계의 AI를 사용합니다.
>
> 1.  **대화 AI:** 사용자와 직접 대화하는 AI입니다.
> 2.  **위험 탐지 AI (Risk Classifier):** 사용자의 모든 메시지는 대화 AI에게 전달됨과 동시에 **별도의 '위험 탐지 AI'**에게도 전송됩니다. 이 AI는 오직 '안전', '주의', '위험', '고위험' 4단계로 즉각적인 분류만 수행합니다.
>
> 만약 '위험' 또는 '고위험'으로 분류될 경우, 시스템은 즉시 **기술적 에스컬레이션**을 실행합니다. 해당 내담자를 담당하는 **인턴 상담사와 슈퍼바이저 모두에게 즉각적인 푸시 알림(Push Notification)과 이메일 경고**를 전송하여 즉각 개입이 가능하도록 설계했습니다. [cite_start]이는 AI의 자동화된 초진 기능 [cite: 3]이 가진 한계를 보완하는 핵심 안전망입니다."
